{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "import argparse\n",
    "import time\n",
    "import copy\n",
    "import math\n",
    "import torchvision.utils as vision_utils\n",
    "import json\n",
    "import numpy as np\n",
    "from torch.distributions import bernoulli\n",
    "from scipy import linalg\n",
    "import torchvision.datasets as _datasets\n",
    "import torchvision.transforms as _transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "\n",
    "from data import Binarize, Smooth, load_mnist, get_sampler\n",
    "from evals import compute_mu_sigma_pretrained_model, calculate_frechet_distance, _calculate_metrics, get_metrics\n",
    "from losses import get_disciminator_loss, get_generator_loss\n",
    "from model import DiscriminatorCNN28, GeneratorCNN28, MLP_mnist, pretrained_mnist_model\n",
    "from trainer import train\n",
    "from updates import Lookahead, update_avg_gen, update_ema_gen\n",
    "from utils import save_models, get_plot_func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-304c451c48e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     32\u001b[0m   plot_func = get_plot_func(out_dir=out_dir, \n\u001b[1;32m     33\u001b[0m                             \u001b[0mimg_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m                             num_samples_eval=10000)\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m   \u001b[0mG\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGeneratorCNN28\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnoise_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_NOISE_DIM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_tanh\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/GAN_LOLA/utils.py\u001b[0m in \u001b[0;36mget_plot_func\u001b[0;34m(out_dir, img_size, num_samples_eval, save_curves)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_plot_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_curves\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_data_root\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'datasets'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinarized\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m   \u001b[0;31m#shutil.rmtree(out_dir, ignore_errors=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m   \u001b[0;31m#if not os.path.exists(out_dir):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_mnist' is not defined"
     ]
    }
   ],
   "source": [
    "args = dict(iterations = 50000,\n",
    "            batch_size = 50,\n",
    "            lrD = 0.001,\n",
    "            lrG = 0.001,\n",
    "            beta1 = 0.05,\n",
    "            extragrad = False,\n",
    "            eval_every = 5000,\n",
    "            lookahead = False,\n",
    "            eval_avg = True,\n",
    "            lookahead_k = 1000,\n",
    "            n_workers = 5,\n",
    "            device = 'cuda',\n",
    "            grad_max_norm = None)\n",
    "\n",
    "\n",
    "for k in range(1,5+1):\n",
    "  exp_key = f\"iter{args['iterations']}_bs{args['batch_size']}_lrD{args['lrD']}\" + \\\n",
    "            f\"_lrG{args['lrG']}_beta1{args['beta1']}_lookahead{args['lookahead']}\" + \\\n",
    "            f\"_lak{args['lookahead_k']}\" + \\\n",
    "            f\"_extragrad{args['extragrad']}_ee{args['eval_every']}\"\n",
    "  out_dir = f\"/home/mila/t/tianyu.zhang/LAGAN-Lookahead_Minimax/mnist/drive/My Drive/results/final/{exp_key}/{k}/\"\n",
    "\n",
    "  shutil.rmtree(out_dir, ignore_errors=True)\n",
    "  if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "  with open(os.path.join(out_dir, 'args.json'), 'w') as fs:\n",
    "    json.dump(args, fs)\n",
    "\n",
    "  dataset = load_mnist(_data_root='datasets', binarized=False)\n",
    "\n",
    "  plot_func = get_plot_func(out_dir=out_dir, \n",
    "                            img_size=dataset[0][0].size(),\n",
    "                            num_samples_eval=10000)\n",
    "\n",
    "  G = GeneratorCNN28(noise_dim=_NOISE_DIM, out_tanh=True)\n",
    "  D = DiscriminatorCNN28(spectral_norm=False, img_size=28)\n",
    "\n",
    "  train(G, D, dataset, \n",
    "        iterations=args['iterations'], \n",
    "        batch_size=args['batch_size'], \n",
    "        lookahead=args['lookahead'],\n",
    "        lookahead_k=args['lookahead_k'],\n",
    "        eval_avg=args['eval_avg'],\n",
    "        lrD=args['lrD'], \n",
    "        lrG=args['lrG'], \n",
    "        beta1=args['beta1'], \n",
    "        extragrad=args['extragrad'],\n",
    "        eval_every=args['eval_every'], \n",
    "        n_workers=args['n_workers'], \n",
    "        device=torch.device(args['device']), \n",
    "        grad_max_norm=args['grad_max_norm'], \n",
    "        plot_func=plot_func,\n",
    "        out_dir=out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
